[["index.html", "Gambling Statistics Introduction", " Gambling Statistics Dan Rogers 2020-10-22 Introduction I remember being about 16 years old, spending a few weeks each summer at Devils Lake with my grandparents. One of the fun things we would do is get the felt casino cover for the table out. It had a Blackjack table on one side and Craps on the other. Grandpa would be the house, calling out our bets, informing us of bad bets, and paying out the winner. During one of those summers, I had just learned about calculating sums for inifinite series. I remember trying to calculate the odds on craps, and realizing it was an infinite series that could be summed just like we had learned in class. This was really quite amazing. While it was widely believed we would never actually use the math we were learning in class, here was a great example of how it can be used in real life That example of using math to calculate the expected returns in craps stands out in my mind as something that really drove my interest in gambling and applying statistics to different games. It wasnt too long after that I was also building computer simulations for games like Blackjack and Poker, trying to re-create basic strategy and the different statistical tables I had seen for Texas Hold Em. Now Ill be the first to admit: this is well-trodden ground that doesnt require any new work or discovery by me. The Wizard of Odds has already calculated statistics and expected returns for pretty much any game you can imagine. There really isnt any value in me going through and calculating them all myself except that I like it. I think its fun, and Ive decided that is reason enough. I intend to put my notes here as I accumulate them, adding a chapter for each game or subject. Theres even a chance that this could turn into a good reference for statistics applied to gambling games. I intend to start with the most basic games and build up to the more complex. So maybe there is some value in arranging the content in this way and emphasizing the math that gets you to the answer rather than just the result. But really, when it comes down to it, I just find this a fun way to spend time, and that is all that matters. "],["flipping-a-coin.html", "1 Flipping a Coin (and Basic Probabilities) 1.1 Overview 1.2 Payouts for Unfair Coins 1.3 Inferring the Bias of a Coin", " 1 Flipping a Coin (and Basic Probabilities) U.S. Quarter 1.1 Overview The simplest game of chance I can imagine is flipping a coin. A fair coin will have a 50% chance of coming up heads and 50% chance of coming up tails. A fair bet is one that pays even money. That means that if you bet $1 on a particular outcome (heads or tails), you win $1 if youre right and lose $1 if youre wrong. In gambling terms the odds are 1-to-1, meaning there is an equal probability of each outcome, and a fair bet will pay 1-to-1, meaning that the dollar you bet is matched with 1 dollar you win. The expected value of such a wager is calculated as: \\[ Expected Value = Pr(win) * (\\$1) + Pr(lose) * (-\\$1) = 0.5 * (\\$1) + 0.5 * (-\\$1) = \\$0 \\] This is the basic means of calculating any expectation in statistics. First, you find the probabilities or each event. Next, you multiply each probability by the expected return in each scenario. And then you add those all together. The difficult part is usually finding the probabilities or each outcome, especially in games that involve players making choices where you also must work to find the optimal choice in any scenario. 1.2 Payouts for Unfair Coins So what if the coin is not a fair coin and is instead biased towards landing on one side more than the other? If we know the probability of it coming up heads, we can adjust our expectation of a bet on heads. Lets say we have a 60% chance of getting heads. We still bet $1 and win $1 if were right. The expected value of our bet is now: \\[ Expected Value = Pr(win) * (\\$1) + Pr(lose) * (-\\$1) = 0.6 * (\\$1) + 0.4 * (-\\$1) = \\$0.20 \\] We can now expect to win $0.20, on average, every time we bet $1 on a flip of the coin. If both players know this, you wont find anyone who is willing to take the bet. Instead, they will want to modify the payout to make it a fair game. The payout that does this will be a 3-to-2 bet. This can easily be inferred from knowing that a game with a 60% probability of winning is providing 3-to-2 odds of winning. That is we expect to win 3 times for every 2 times we lose (which is the same as saying we expect to win 60 times for every 40 we lose, but reduced as a fraction to simplest terms). If an event occurs with odds 3-to-2, a fair payout is the inverse: 2-to-3. This means that we have to wager $3 in order to win $2: \\[ Expected Value = 0.6 * (\\$2) + 0.4 * (-\\$3) = \\$0 \\] Or if we want to stick with our original bet, we can still wager $1, but the payout if we win will only be 2/3 of that: \\[ Expected Value = 0.6 * (\\$1 * 2/3) + 0.4 * (-\\$1) = \\$0 \\] NOTE: Understanding the differences between probabilities of events occurring, the odds of events occurring, and the payouts for different bets are going to be key in our analysis of pretty much any game. Make sure you understand why an event that has a 60% chance of occurring also has 3-to-2 odds of occurring. This can be somewhat confusing at first. 1.3 Inferring the Bias of a Coin 1.3.1 Maximum Likelihood Estimates Inferring the bias of a coin can be as easy or as complex as you would like to make it. The easiest way to estimate the bias of a coin is to flip it a large number of time (maybe a thousand or a million) and record the percentage of times it comes up heads and the percentage of times it comes up tails. The law of large numbers says that in the long run over a large number of trials the overall proportion of events should come increasingly close to their underlying probability of occurring (assuming those probabilities are constant). But what if you only flip a coin 10 times and observe it come up heads 7 out of those 10 times? Now you are in a tricky spot where you must determine if you truly have enough information from those 10 trials to reliably infer the probability of heads or tails. If we want to estimate the probability of heads in this case, the maximum likelihood estimate is 70%. This means that if we assume the probability of heads is 70% and then calculate the likelihood of getting 7 heads and 3 tails in 10 trials, the likelihood will be higher with this estimate of the coins bias than with any other estimate. The maximum likelihood estimate for the probability will always be: \\[ Pr(X=x) = \\frac{\\sum\\limits_{n=1}^{N}{(X_n=x)}}{N} \\] That is, we count the number of times the event occurs in N trials and express that as a percentage of the total number of trials. But is this past evidence really enough to say this is the best answer? What if we only have 1 coin flip and it came up heads? The maximum likelihood estimate now is 100% that heads will come up every time. This yields the highest likelihood for our observed data (our 1 trial), but it intuitively is a very bad guess. 1.3.2 Getting Bayesian With It The best way to deal with this type of uncertainty is to use Bayesian statistics. These allow us to combine what we have observed in the data with whatever pre-conceived beliefs we might have about the situation. If we believe that a 100% probability of heads is unlikely, we can include that bias in our calculations. We might be wrong, but it will take a large amount of evidence to convince us. The amount of evidence it takes will correlate with how strong our bias is that this should not happen. But even if we start with the belief that the coin will not always flip to heads, if we perform 1,000 trials and see heads every time, we will increasingly become convinced that this is true. Although it is a powerful way to analyze probabilities, Bayesian methods can be tricky, however, The hardest part is finding a way to quantify your prior expectations mathematically. How sure are you that the coin is likely to be fair? Maybe you distrust the person you are playing against and actually suspect them to have an unfair coin. In that case, how unfair do you think the coin is likely to be? There is no right answer to these questions. They are all subjective. Therefore there is no correct way to solve this problem. Every solution depends on our pre-conceived bias or beliefs and the manner in which we choose to quantify those, and it is possible for us to influence the outcome as little or as much as wed like with those prior beliefs. There is a good example of what this looks like here, including R code to reproduce the results. On this page they use a discrete set of possibilities that model the probability of flipping heads as either 0%, 10%, 20%,  up to 100%. They start with a triangular probability distribution that favors a 50% probability and rules out the 0% and 100% altogether, setting their probabilities to zero. They then update this prior periodically with new experimental data and show you how the prior probabilities start to evolve. In general, the probability distribution will begin to shift in a way that it begins to favor the maximium likelihood estimator, but in a way that still incorporates our prior beliefs and allows for other possibilities. In a similar manner, lets see what happens if we start with a uniform prior, meaning that we have no idea whether the coin is fair or completely biased. x_values &lt;- seq(0, 1, 0.1) # discrete values we will model pdf_prior &lt;- rep(1/length(x_values), length(x_values)) avg_value &lt;- weighted.mean(x_values, pdf_prior) print(paste0(&quot;Expecte Value = &quot;, avg_value)) ## [1] &quot;Expecte Value = 0.5&quot; As we can see, this simple prior also essentially assumes the coin is fair. Now, lets build a function to update our prior based on new data. First, we will need to calculate the likelihood of our data under each of our models (each of our possible values of x): get_likelihoods &lt;- function(x_values, num_heads, num_tails) { dbinom(num_heads, num_heads+num_tails, x_values) } Next, we will need to build an update function that applies Bayes Theorem: \\[ Pr(\\Theta | D) = \\frac{Pr(D | \\Theta) Pr(\\Theta)}{Pr(D)} \\] This tells us that the probability of our model (\\(\\Theta\\)) given the data (D), can be inferred from the probability (or likelihood) or our data given our model, our prior beliefs about the probability of of the model being right, and the probability of the data itself. In our case, this function will be: update_priors &lt;- function(x_values, priors, num_heads, num_tails) { likelihoods &lt;- get_likelihoods(x_values, num_heads, num_tails) priors &lt;- (priors * likelihoods) / sum(priors * likelihoods) priors } trials &lt;- tibble::tribble( ~heads, ~tails, 1, 0, 0, 1, 2, 3, 1, 4, 5, 5, 6, 4, 4, 6, 9, 1, 10, 10, 15, 5, 19, 1, 20, 0, 50, 50, 60, 40, 90, 10, 100, 0 ) avg_posterior &lt;- rep(NA_real_, nrow(trials)) for (i_row in 1:nrow(trials)) { pdf_posterior &lt;- update_priors(x_values, pdf_prior, trials$heads[i_row], trials$tails[i_row]) avg_posterior[i_row] &lt;- weighted.mean(x_values, pdf_posterior) } knitr::kable(data.frame( n = trials$heads + trials$tails, heads = trials$heads, tails = trials$tails, mle = trials$heads / (trials$heads + trials$tails), avg_posterior = avg_posterior )) n heads tails mle avg_posterior 1 1 0 1.00 0.7000000 1 0 1 0.00 0.3000000 5 2 3 0.40 0.4287129 5 1 4 0.20 0.2928934 10 5 5 0.50 0.5000000 10 6 4 0.60 0.5833635 10 4 6 0.40 0.4166365 10 9 1 0.90 0.8180324 20 10 10 0.50 0.5000000 20 15 5 0.75 0.7273362 20 19 1 0.95 0.8782598 20 20 0 1.00 0.9870205 100 50 50 0.50 0.5000000 100 60 40 0.60 0.5976159 100 90 10 0.90 0.8975115 100 100 0 1.00 0.9999973 We can see that Bayesian updates swing pretty quickly with only 1 observation, moving toward a 70% probability for whichever side of the coin it saw come up first. With more data it starts to go closer to the maximum likelihood estimate. In this case even after 5 flips of the coin we are pretty close to the MLE, 42.8% versus 40% when we see 2 out of 5 come up heads and 29.3% versus 20% when we see 1 out of 4 come up heads. In this case we move quickly towards the MLE because we did not specify a strong preference for any of the models in our prior. We do see that the model is rather unwilling to go too far to the extremes though. When 20 out of 20 trials all turn up heads, it is only willing to go as far as a 98.7% probability of heads, leaving room for tails to still appear on the next toss. Even after 100 out of 100 trials all turn up heads, it still leaves the tiniest probability that tails still might occur. My brother told me once that he was reading the book Probability Theory: The Logic of Science by E.T. Jaynes and that it started with an opening chapter on probabilities for flipping coins. One interesting question Jaynes asked was: what is the probability that the coin will land on its edge and be neither heads nor tails? Now, we might toss a coin a million times and never see these happen, but that doesnt mean that it is impossible. Jaynes proposed a Bayesian approach that could begin with some assumption about the probability of this event. Perhaps we give it a 1% probability. Then we can run our million tests, update our probabilities, and even if we never see it occur, there will still be a non-zero probability that it could occur on the next roll. This is an interesting way to include potential outcomes in your model even when they have never been witnessed before. Ultimately, we can be sure of one thing: flipping a coin is not as trivial mathematically as it might first appear. There are all kinds of good statistical lessons that can be learned from this simple experiment. "],["problem-of-points.html", "2 Problem of Points 2.1 Overview 2.2 Solution 2.3 Inferring a Players Advantage 2.4 Historical Notes", " 2 Problem of Points 2.1 Overview My brother once told me about a story from the early days of probability theory. It involved Blaise Pascal and Pierre de Fermat writing letters to each other in 1654 about how to settle a theoretical game that was prematurely ended before a winner could be declared. In one variation of the game, two gamblers have each wagered 32 pistoles (gold pieces) in a game where the first person to win 3 rounds wins. Each player has a 50/50 chance of winning each round, but the game is prematurely ended at a point where one player has 2 wins and the other has 1 win. The problem is: what is the fairest way to divide the 64 pistoles? This question of how to divide the winnings of an unfinished game is called the problem of points or the division of the stakes. There is a good Wikipedia article on it here. It is mentioned that a naive solution such as divide the winnings based on the proportion each player has won so far is flawed because a player who has won only a single game will get the entire reward if his opponent has not won at all. This will be true even if there are many games left to play such that the overall advantage the first player has won is negligible. Intuitively, it is reasoned that the answer must be based on the number of games left to play and the relative advantage one player has over the other. For instance, in a game to 10, if the first player has won 7 times and the second player has won 5 times, the situation is essentially the same as a game to 20 where the first player has 17 and the second has 15. In each case the first player needs to win 5 games to win and the second player needs to win 7. These are the numbers that intuitively should matter and the division of winnings should be the same in both of these scenarios. 2.2 Solution The solution can be found by exploring every possible way that the remaining games could be played out and seeing how many of these result in each player winning. This was the method that Fermat used in his solution. We can write a simple recursive function in Python to compute this: def get_expected_value(p1_wins, p2_wins, goal): &quot;&quot;&quot;Return the probability that player 1 wins given that player 1 currently has p1_wins and player 2 has p2_wins and that the game is won when they reach &quot;goal&quot; number of wins. &quot;&quot;&quot; if (p1_wins == goal): return 1 elif (p2_wins == goal): return 0 p1 = get_expected_value(p1_wins + 1, p2_wins, goal) p2 = get_expected_value(p1_wins, p2_wins + 1, goal) return (p1 + p2) / 2 This yields the following solutions for some of the cases we have discussed: P1 Wins P2 Wins Goal Pr(P1 Wins All) 7 5 10 77.34375% 17 15 20 77.34375% 2 1 3 75% 5 3 6 87.5% In general, you can also use the following equation to find the probability of player 1 winning if player 1 has \\(s_1\\) rounds left to win and player 2 has \\(s_2\\) rounds left to win where \\(p_1\\) is the probability of player 1 winning a game and \\(p_2\\) is the probability of player 2 winning: \\[ \\sum\\limits_{k=s_1}^{s_1+s_2-1}{\\frac{s_1+s_2-1}{k}(p_{1})^{k}(p_{2})^{s_1+s_2-1-k}} \\] 2.3 Inferring a Players Advantage In the classical form of the problem, we assume that each player has an equal chance of winning a round, but what if that was not the case? If we are playing to 1,000 and one player has won 750 times to the other players 100, should we infer that the first player is actually better than the second and more likely to win future matches? This problem is essentially identical to the coin flipping problem. We want to estimate the probability of each player winning future rounds based on their past performance. We can use the maximum likelihood estimate that simply uses the percentage of past wins as the predictor of future probabilities. We could also start with a Bayesian prior and update that based upon the observed data. In this case there are an infinite number of ways to setup the prior probabilities, and thus an infinite number of ways to solve this problem based upon not only the observed data but our prior expectations about how fairly matched the players are. 2.4 Historical Notes The actual text of the letters between Pascal and Fermat can be found here. There is also a good overview in the American Physical Societys article This Month in Physics History subtitled July 1654: Pascals Letters to Fermat on the Problem of Points(Volume 18, Number 7, July 2009). This goes into more detail about how the problem was first proposed in 1494 by an Italian monk named Luca Paccioli. The question was being pondered in 1654 by an amateur mathematician who enjoyed gambling named Antoine Gombaud. It was Gombaud who asked his friend Pascal, who also had taken an interest in gambling, and it was this question that spurred the letters. The original question that Paccioli asked concerned a game of balla, which requires six goals to win the game, shoul d be settled if the game is stopped when one player has 5 goals and the other has 3. "],["roulette.html", "3 Roulette", " 3 Roulette Roulette Table Roulette is a fun and simple game where a large wheel is spun and then a ball is dropped into the wheel. Players bet on where the ball will land. The main numbers range from 1 to 36 and are divided into half red and half black. There is also an additional number: zero that is neither red nor black (nor is it even or odd). In most games, you will find zero (0) and double zero (00). The presence of these numbers is what gives the house its edge in the game. There are a variety of bets that can be made in Roulette: Red or black, paying 1-to-1 Even or odd, paying 1-to-1 Any single number (Straight Up), paying 35-to-1 Two adjacent numbers (Split), paying 17 to 1 Three numbers in a row (Street), paying 11 to 1 Four adjoining numbers (Corner), paying 8 to 1 Twelve numbers, either sequential (Dozen) or in a Column, paying 2 to 1 1-18 or 19-36, paying 1-to-1 Interestingly, the expected return on all of these bets is exactly the same. To show why this is true, lets calculate a few. First, well calculate my favorite bet: red or black, paying even money. \\[ Expected Value = \\frac{18}{38} * (\\$1) + \\frac{20}{38} * (-\\$1) = -\\frac{2}{38} = -0.05263158 \\] Notice that this bet is almost like flipping a coin (1). In fact, if the zeroes were not on the board and we only had 36 numbers, it would be identical. However, the presence of the zeroes means that we have 38 outcomes, not 36, and the 2 new outcomes that are introduced by the presence of the zero are losses for us. This turns the expected return slightly negative, giving the house a 5.26% edge. However much money we place on this bet, we should expect to lose an average of 5.26% with each spin of the wheel. Lets calculate another one. Obviously, the even or odd bet will be the same. So lets do a straight up bet on a single number. The expected return in this case is: \\[ Expected Value = \\frac{1}{38} * (\\$35) + \\frac{37}{38} * (-\\$1) = -\\frac{2}{38} = -0.05263158 \\] As suggested, this is the the same house edge as the red/black or even/odd bet. Knowing that the payout on any bet is equal to the true odds in the absence of the zeroes, we can see that this will always come out the same way. Just to demonstrate this, here are the expected values for bets place on 4 and 12 numbers: \\[ Expected Value = \\frac{4}{38} * (\\$8) + \\frac{34}{38} * (-\\$1) = -\\frac{2}{38} = -0.05263158 \\] \\[ Expected Value = \\frac{12}{38} * (\\$2) + \\frac{26}{38} * (-\\$1) = -\\frac{2}{38} = -0.05263158 \\] So far we have analyzed American roulette, which has both zero and double zero. European roulette instead only has 1 zero. Intuitively, we know that this will improve our odds. Specifically, we find that a single number bet now has the expected value: \\[ Expected Value = \\frac{1}{37} * (\\$1) + \\frac{36}{37} * (-\\$1) = -\\frac{1}{37} = -0.02702703 \\] The house edge has been cut almost in half, from 5.26% to 2.70%. As with American roulette, all of the other bets will have this same expected value and house edge. Obviously, it is advantageous to players to play at European style tables whenever possible. "],["craps.html", "4 Craps 4.1 Dice Odds 4.2 Single Roll (proposition) Bets 4.3 Multi-Roll Bets 4.4 Line Bets 4.5 Summary", " 4 Craps Craps Table As mentioned in the introduction, craps is the game that fascinated me the most in terms of how it could be modeled mathematically. There are a variety of bets in craps. Wikipedia divides them into three types: Line Bets (pass line, dont pass line, come line, and dont come line) Multi-Roll Bets (place and hard way bets) Single-Roll Bets The single-roll bets are the easiest to analyze, so well start there. But the line bets (in particular the pass line) is where things really get fun. 4.1 Dice Odds Since we havent discussed this previously, lets take a quick detour and discuss the odds of different outcomes when rolling a pair of die. The outcomes and probabilities of each outcome are shown below: Outcome Ways to Roll It Probability 2 1 \\[ \\frac{1}{36} \\approx 2.78\\% \\] 3 2 \\[ \\frac{2}{36} \\approx 5.56\\% \\] 4 3 \\[ \\frac{3}{36} \\approx 8.33\\% \\] 5 4 \\[ \\frac{4}{36} \\approx 11.11\\% \\] 6 5 \\[ \\frac{5}{36} \\approx 13.89\\% \\] 7 6 \\[ \\frac{6}{36} \\approx 16.67\\% \\] 8 5 \\[ \\frac{5}{36} \\approx 13.89\\% \\] 9 4 \\[ \\frac{4}{36} \\approx 11.11\\% \\] 10 3 \\[ \\frac{3}{36} \\approx 8.33\\% \\] 11 2 \\[ \\frac{2}{36} \\approx 5.56\\% \\] 12 1 \\[ \\frac{1}{36} \\approx 2.78\\% \\] Notice that the most likely outcome of any roll is 7. This is important in craps where many bets are either betting for or betting against a 7 being thrown. The least likely numbers to occur are 2 and 12 since there is only one combination of the die that result in each of these. 4.2 Single Roll (proposition) Bets Single roll bets are the easiest to analyze because you only bet on one throw of the die. You either win or lose based on the outcome, and the results can be calculated very easily. Examples of these bets include: Field Service Bets (the bets in the middle, including snake eyes, box cars, and other specific outcomes) C&amp;E Bets 4.2.1 Service Bets Once again, well start with the easiest of these: the service bets. These are the bets in the middle of the table. They show a specific outcome (such as snake eyes or box cars) and the payout for winning. The table below quickly summarizes the results of these bets: Bet Payout Probability Expected Return 2, 12 30 to 1 \\[ \\frac{1}{36} \\approx 2.78\\% \\] \\[ \\frac{30}{36} - \\frac{35}{36} = -\\frac{5}{36} \\approx -13.89\\% \\] 3, 11 15 to 1 \\[ \\frac{2}{36} \\approx 5.56\\% \\] \\[ \\frac{15*2}{36} - \\frac{34}{36} = -\\frac{4}{36} \\approx -11.11\\% \\] Any Craps 7 to 1 \\[ \\frac{4}{36} \\approx 11.11\\% \\] \\[ \\frac{7*4}{36} - \\frac{32}{36} = -\\frac{4}{36} \\approx -11.11\\% \\] Any 7 4 to 1 \\[ \\frac{6}{36} \\approx 16.67\\% \\] \\[ \\frac{4*6}{36} - \\frac{30}{36} = -\\frac{6}{36} \\approx -16.67\\% \\] 4.2.2 C&amp;E The C&amp;E bet is a combined bet where you are betting half your money on craps and half on eleven. The payouts on each half of the bet are the same as in the service bet table. The result is that a craps win pays out 3-to-1 and a win on 11 pays out 7-to-1. To understand why, imagine you bet $2 and roll craps. The $1 you bet on craps returns 7-to-1, but you lose the $1 you bet on 11. This means you get $6 for your $2 bet. If you bet $2 and roll 11, the $1 you bet here wins $15. You lose the $1 you bet on craps, so you get $14 back for your $2 bet. With these modified payouts in mind, here are the expectations of this bet: Outcome Payout Probability Result Craps $3 \\[ \\frac{4}{36} \\approx 11.11\\% \\] \\[ \\frac{12}{36} \\approx 0.3333 \\] 11 $7 \\[ \\frac{2}{36} \\approx 5.56\\% \\] \\[ \\frac{14}{36} \\approx 0.3389 \\] Lose -$1 \\[ \\frac{30}{36} \\approx 83.33\\% \\] \\[ -\\frac{30}{36} \\approx -0.8333 \\] Total 100% \\[ -\\frac{4}{36} \\approx -0.1111 \\] The result is a -11.11% return. This shouldnt be surprising since this is the same return on the 11 bet and the Any Craps bet individually. If we bet them as a combined bet, we should expect the same return. 4.2.3 Field The Field bet is a one-roll bet that wins if you roll a 2, 3, 4, 9, 10, 11, or 12. The bet pays even money on everything except the 2 and 12. These will either both pay 2-to-1 or the 2 will pay 2-to-1 and the 12 will pay 3-to-1. The outcomes and payouts for both pay schedules are shown below: Outcome Probability Payout (2-to-1 on 12) Payout (3-to-1 on 12) 12 \\[ \\frac{1}{36} \\approx 2.78\\% \\] $2 $3 2 \\[ \\frac{1}{36} \\approx 2.78\\% \\] $2 $2 3, 4, 9, 10, 11 \\[ \\frac{2+3+4+3+2}{36} = \\frac{14}{36} \\approx 38.89\\% \\] $1 $1 5, 6, 7, 8 \\[ \\frac{4+5+6+5}{36} = \\frac{20}{36} \\approx 55.56\\% \\] -$1 -$1 If you do the weighted sum (probability * payout) you will find the following expected returns: 2-to-1 on 12 : \\(\\frac{2+2+14-20}{36} = -\\frac{2}{36} \\approx -5.56\\%\\) 3-to-1 on 12 : \\(\\frac{3+2+14-20}{36} = -\\frac{1}{36} \\approx -2.78\\%\\) 4.3 Multi-Roll Bets Multi-roll bets are typically bets that a specific number will be rolled before rolling a 7. An example of these are the hard way bets where you can bet that a 4 will be rolled as doubles before a 7. The bet will not resolve until one of these events happens, meaning that several rolls of the die are likely to occur before you win or lose. This is where we will need to make use of our formulas for summing infinite series. Specifically, we will need the formula for the sum of a geometric series: \\[ \\sum\\limits_{k=0}^{\\infty}{r^{k}} = \\frac{1}{1-r} \\] which is applicable when $ |r| &lt; 1 $ . 4.3.1 Big 6 &amp; Big 8 Big 6 and Big 8 bets are notoriously bad bets. Experienced players avoid them (and some casinos dont even put them on the table) because you can make a place bet that is effectively the same bet with a better payout. However, these are easy ones with which we can begin our multi-roll outcome analysis. The big 6 bet wins if a 6 comes up before a 7. Similarly, the big 8 bet wins if an 8 comes up before a 7. Since 6 and 8 are equally-likely to be rolled, we can calculate their odds together. Each bet pays even money. On any roll we have the following 3 outcomes: Outcome Probability Win \\[ \\frac{5}{36} \\approx 13.89\\% \\] Lose \\[ \\frac{6}{36} \\approx 16.67\\% \\] Continue \\[ \\frac{25}{36} \\approx 69.44\\% \\] Eventually, we will have to either win or lose, although we may have any number of continue rolls occur before that final result. This means that the odds of winning are: \\[ \\frac{5}{36} + \\frac{25}{36} \\frac{5}{36} + (\\frac{25}{36})^{2} \\frac{5}{36} + \\dots = \\frac{5}{36} \\sum\\limits_{k=0}^{\\infty}{(\\frac{25}{36})^{k}} \\] The first term in this infinite series represents the probability of winning on the first roll; the second term, the second roll; etc.. We can use the formula for summing an infinite series to get the total probability of winning as: \\[ \\frac{5}{36} \\sum\\limits_{k=0}^{\\infty}{(\\frac{25}{36})^{k}} = \\frac{5}{36} \\frac{1}{1-\\frac{25}{36}} = \\frac{5}{36} \\frac{36}{11} = \\frac{5}{11} \\approx 45.45\\% \\] While we know that the odds of losing must be the complement of this (\\(\\frac{6}{11}\\)) we can also work these out the long way and sum them as an infinite series as well. The result will be: \\[ \\frac{6}{36} \\sum\\limits_{k=0}^{\\infty}{(\\frac{25}{36})^{k}} = \\frac{6}{36} \\frac{1}{1-\\frac{25}{36}} = \\frac{6}{36} \\frac{36}{11} = \\frac{6}{11} \\approx 54.54\\% \\] This means that the expected return of this bet is: \\[ \\frac{5}{11} * 1 + \\frac{6}{11} * (-1) = -\\frac{1}{11} \\approx 9.09\\% \\] 4.3.2 Hard-Way Bets Hard-way bets pay out if you roll a specific number (4, 6, 8, or 10) the hard way (i.e. as doubles) before you roll it the soft way or roll a 7. The odds for 4 and 10 are the same, as they are also for 6 and 8. The table below illustrates the outcomes and probabilities for 4 and 10: Outcome Probability Win \\[ \\frac{1}{36} \\approx 2.78\\% \\] Lose \\[ \\frac{6}{36} + \\frac{2}{36} = \\frac{8}{36} \\approx 22.22\\% \\] Continue \\[ \\frac{27}{36} = 75\\% \\] This means the total probability of winning is: \\[ \\frac{1}{36} \\sum\\limits_{k=0}^{\\infty}{(\\frac{27}{36})^{k}} = \\frac{1}{36} \\frac{1}{1-\\frac{27}{36}} = \\frac{1}{36} \\frac{36}{9} = \\frac{1}{9} \\approx 11.11\\% \\] This bet pays out 7-to-1. The expected return is thus: \\[ \\frac{1*7}{9} - \\frac{8}{9} = -\\frac{1}{9} \\approx -11.11\\% \\] When betting hard 6 or 8 the outcomes are as shown: Outcome Probability Win \\[ \\frac{1}{36} \\approx 2.78\\% \\] Lose \\[ \\frac{6}{36} + \\frac{4}{36} = \\frac{10}{36} \\approx 27.78\\% \\] Continue \\[ \\frac{25}{36} \\approx 69.44\\% \\] This means the total probability of winning is: \\[ \\frac{1}{36} \\sum\\limits_{k=0}^{\\infty}{(\\frac{25}{36})^{k}} = \\frac{1}{36} \\frac{1}{1-\\frac{25}{36}} = \\frac{1}{36} \\frac{36}{11} = \\frac{1}{11} \\approx 9.09\\% \\] The probability of winning on a hard 6 or 8 is lower than that of a 4 or 10 because there are more soft ways to roll these numbers and thus higher probabilities of losing. The payout is higher though, at 9-to-1 it gives the following expected return: \\[ \\frac{1*9}{11} - \\frac{10}{11} = -\\frac{1}{11} \\approx -9.09\\% \\] NOTE: Many craps tables (including the image in this section) show the odds as 8 to 1 for the hard 4 and 10 and 10 to 1 for hard 6 and 8. These really mean 8 for 1 and 10 for 1 which are the equivalent of 7 to 1 and 9 to 1. 4.3.3 Place Bets Place bets can be made on the numbers 4, 5, 6, 8, 9, and 10. These are bets that the corresponding number will be rolled before a 7. The payouts for these bets are 9-to-5 on 4 or 10, 7-to-5 on 5 or 9, and 7-to-6 on 6 or 8. (You can now see why the Big 6 and Big 8 bets are discouraged since you can make the same bet here and get a 7-to-6 payout rather than even money.) The probabilities of outcomes for different points are shown below: Point Win Lose Continue 4 or 10 \\[ \\frac{3}{36} \\approx 8.33\\% \\] \\[ \\frac{6}{36} \\approx 16.67\\% \\] \\[ \\frac{27}{36} = 75\\% \\] 5 or 9 \\[ \\frac{4}{36} \\approx 11.11\\% \\] \\[ \\frac{6}{36} \\approx 16.67\\% \\] \\[ \\frac{26}{36} \\approx 72.22\\% \\] 6 or 8 \\[ \\frac{5}{36} \\approx 13.89\\% \\] \\[ \\frac{6}{36} \\approx 16.67\\% \\] \\[ \\frac{25}{36} \\approx 69.44\\% \\] The probability of winning on 4 or 10 is: \\[ \\frac{3}{36} \\sum\\limits_{k=0}^{\\infty}{(\\frac{27}{36})^{k}} = \\frac{3}{36} \\frac{1}{1-\\frac{27}{36}} = \\frac{3}{36} \\frac{36}{9} = \\frac{3}{9} \\approx 33.33\\% \\] The expected return is: \\[ [\\frac{1}{3}(9) + \\frac{2}{3}(-5)] / 5 = -\\frac{1}{15} \\approx -6.67\\% \\] Note that we divide by 5 when calculating this return because we calculated returns on a $5 bet. In order to get this as a percentage that is relevant to any bet size we divide by the amount bet. When 5 or 9 is the point, we have: \\[ \\frac{4}{36} \\sum\\limits_{k=0}^{\\infty}{(\\frac{26}{36})^{k}} = \\frac{4}{36} \\frac{1}{1-\\frac{26}{36}} = \\frac{4}{36} \\frac{36}{10} = \\frac{4}{10} = 40\\% \\] and the expected return: \\[ [\\frac{4}{10}(7) + \\frac{6}{10}(-5)] / 5 = -\\frac{2}{50} = 4\\% \\] When 6 or 8 is the point, we have: \\[ \\frac{5}{36} \\sum\\limits_{k=0}^{\\infty}{(\\frac{25}{36})^{k}} = \\frac{5}{36} \\frac{1}{1-\\frac{25}{36}} = \\frac{5}{36} \\frac{36}{11} = \\frac{5}{11} \\approx 45.45\\% \\] and the expected return: \\[ [\\frac{5}{11}(7) + \\frac{6}{11}(-6)] / 6 = -\\frac{1}{66} \\approx 1.52\\% \\] To summarize, we have: Point Payout Probability of Win Expected Return 4 or 10 9-to-5 \\[ \\frac{3}{9} \\approx 33.33\\% \\] \\[ -\\frac{1}{15} \\approx -6.67\\% \\] 5 or 9 7-to-5 \\[ \\frac{4}{10} = 40\\% \\] \\[ -\\frac{2}{50} = -4\\% \\] 6 or 8 7-to-6 \\[ \\frac{5}{11} \\approx 45.45\\% \\] \\[ -\\frac{1}{66} \\approx -1.52\\% \\] 4.3.4 Buy Bets A buy bet is similar to a place bet except that it pays true odds. In exchange for this, the house takes a 5% commission. According to Wikipedia, the minimum bet is usually $20 so that the house can easily take its $1 commission. The Wizard of Odds calculates the odds as if he gave the house $1 but left $20 on the table for is bet (a 4.76%) commission. We will proceed using this same calculation. When the point is 4 or 10 we then have: \\[ [\\frac{1}{3}(39) + \\frac{2}{3}(-21)] / 21 = -\\frac{1}{21} \\approx -4.76\\% \\] NOTE: We divide by 21 in the equation because we are betting $21. When we lose, we lose all $21 that we bet. When we win, we should win true odds (2 to 1) for a payout of $40. We get $60 total coming back our way, but we spent $21. This means we really only have a gain of $39. When the point is 5 or 9 we have: \\[ [\\frac{4}{10}(29) + \\frac{6}{10}(-21)] / 21 = -\\frac{1}{21} = -4.76\\% \\] This is similar to before. The odds of winning are 4-to-6, so the true odds payout is 6-to-4. This means we win $30 on our $20 bet that is left after paying the $1 commission. This means the total gain on our bet when we win is $29. When the point is 6 or 8 we have: \\[ [\\frac{5}{11}(23) + \\frac{6}{11}(-21)] / 21 = -\\frac{1}{21} \\approx -4.76\\% \\] Now the odds of winning are 5-to-6, meaning the true odds payout is 6-to-5. This means we win $24 on our $20 bet and have $23 gain when we win. To summarize, we have: Point Payout Probability of Win Expected Return 4 or 10 2-to-1 \\[ \\frac{1}{3} \\approx 33.33\\% \\] \\[ -\\frac{1}{21} \\approx -4.76\\% \\] 5 or 9 3-to-2 \\[ \\frac{2}{5} = 40\\% \\] \\[ -\\frac{1}{21} \\approx -4.76\\% \\] 6 or 8 6-to-5 \\[ \\frac{5}{11} \\approx 45.45\\% \\] \\[ -\\frac{1}{21} \\approx -4.76\\% \\] The probabilities of winning are the same as with the place bets. The expected returns are actually worse on most of these bets though - everything except when the point is a 4 or 10. 4.4 Line Bets Finally, we get to the main bet in craps: the pass line bet (and its derivatives). 4.4.1 Pass Line The pass line bet is a bet that wins immediately when you roll a 7 or 11 and loses immediately if you roll craps (2, 3, or 12). If you roll any other number, that number becomes the point and you win if you roll it again before rolling a 7. The payout is even money. Well have to deal with this bet in two parts. First, we will examine the initial roll - since it is so different from the rest. Then we can look at the remaining rolls where the player is trying to roll their point before rolling a 7. This part of the game will be identical in its probabilities to the place and buy bets we examined previously. On the first roll, we have the following outcomes: Outcome Probability Win (7 or 11) \\[ \\frac{6+2}{36} = \\frac{2}{9} \\approx 22.22\\% \\] Lose (2, 3, or 12) \\[ \\frac{1+2+1}{36} = \\frac{1}{9} \\approx 11.11\\% \\] Continue \\[ \\frac{2}{3} \\approx 66.67\\% \\] We have already calculated the probabilities of rolling a specific point before rolling a 7. These are the probabilities that will determine whether we win if do not immediately win or lose on the first roll. As a reminder, these probabilities are: Point Probability of Occurring Probability of Win 4 or 10 \\[ 2 * \\frac{3}{36} = \\frac{1}{6} \\approx 16.67\\% \\] \\[ \\frac{1}{3} \\approx 33.33\\% \\] 5 or 9 \\[ 2 * \\frac{4}{36} = \\frac{2}{9} \\approx 22.22\\% \\] \\[ \\frac{2}{5} = 40\\% \\] 6 or 8 \\[ 2 * \\frac{5}{36} = \\frac{5}{18} \\approx 27.78\\% \\] \\[ \\frac{5}{11} \\approx 45.45\\% \\] Any \\[ \\frac{3+4+5}{18} = \\frac{2}{3} \\approx 66.67\\% \\] \\[ \\frac{134}{330} \\approx 40.61\\% \\] The very last number in the table might need explaining. This is calculated by multiplying the probability of each event by the probability of winning, summing them up, and then dividing by the total probability of these events. The first sum gives us: \\[ \\frac{1}{6}\\frac{1}{3} + \\frac{2}{9}\\frac{2}{5} + \\frac{5}{18}\\frac{5}{11} = \\frac{268}{990} \\approx 27.07\\% \\] This is the probability of establishing a point and then winning. If we just want the probability of winning given that we have established a point already, we need to divide by \\(\\frac{2}{3}\\), which is the probability of establishing a point in the first place. This gives that final probability of winning as \\(\\frac{134}{330}\\). We now have all the information we need to calculate the total probability of winning this bet. It is equal to the probability of winning on the first roll (\\(\\frac{2}{9}\\)) plus the probability of establising a point (\\(\\frac{2}{3}\\)) multiplied by the probability of winning once that point is established (\\(\\frac{134}{330}\\)). This is: \\[ \\frac{2}{9} + \\frac{2}{3}\\frac{134}{330} = \\frac{448}{990} = \\frac{244}{495} \\approx 49.29\\% \\] The expected value of this bet is then: \\[ \\frac{244}{495} - \\frac{251}{495} = -\\frac{7}{495} \\approx -1.41\\% \\] This is one of the best bets in the casino. It has a very low house edge. It is definitely better than any of the other bets we have calculated so far in craps. And with pass odds, it can get even better. 4.4.2 Pass odds Pass odds is a bet that can be made behind the pass line once a point is established. This is a bet that the point will be made before rolling a 7. Unlike any other bet in the game (or in the casino), this bet pays true odds. This means it pays 2-to-1 on 4 and 10, 3-to-2 on 5 and 9, and 6-to-5 on 6 and 8. As grandpa would say: Youre an idiot if you dont make this bet. Its the best bet in the house. Youll want to make sure you bet enough to get the full payout. A bet of $10 is enough to do this regardless of the point. Casinos typically limit how much you are allowed to bet here. Common limitations are single odds (equal to your pass line bet) and double odds (equal to twice your pass line bet). Some will offer higher limits though or even no limit at all. If you combine this bet with your original pass line bet and calculate the total return, the house edge will shrink below 1.41%. The larger your pass odds bet, the smaller the house edge. This is because the house is only making money off your original bet. There is no house edge on your pass odds bet. Lets calculate the expected return on a pass line bet combined with an odds bet behind it. First, well bring back the equation for the expected return on a pass line bet: \\[ \\frac{2}{9}(1) + \\frac{1}{9}(-1) + \\frac{2}{3}(\\frac{134}{330}(1) + \\frac{196}{330}(-1)) \\] Remember the terms in this equation relate to: Winning on the first roll (\\(\\frac{2}{9}\\)) Losing on the first roll (\\(\\frac{1}{9}\\)) Continuing beyond the first roll (\\(\\frac{2}{3}\\)) to: Win (\\(\\frac{134}{330}\\)) Lose (\\(\\frac{196}{330}\\)) We could try to add in terms that reflect the payout on the pass odds bet. These would only be relevant in the cases where we continue beyond the first roll (which only happens \\(\\frac{2}{3}\\) of the time). While the payouts vary based on the point, the expected value of the payouts on the pass odds bet do not change. They are always zero. If the point were 4 the expected value of our pass odds bet is: \\[ \\frac{1}{3}(2) + \\frac{2}{3}(-1) = 0 \\] So if we do add these terms into the second half of the equation they will all disappear, leaving us with the original equation. The one thing that does change though is the amount of money we bet. In \\(\\frac{1}{3}\\) of the cases, we will win after the first roll, meaning we stick with our original bet of $1. In \\(\\frac{2}{3}\\) of the cases we will get to put another bet behind the line, increasing our total bet to $2. The weighted average of these is: \\[ \\frac{1}{3}(1) + \\frac{2}{3}(2) = \\frac{5}{3} \\] This is the average amount we will bet on any hand. Dividing our original equation by this to get it in terms of the amount bet yields: \\[ -\\frac{7}{495} / \\frac{5}{3} = -\\frac{7}{825} \\approx 0.81\\% \\] Similarly, if we are allowed to double-down behind the line, our overall return based on the money in play is now: \\[ -\\frac{7}{495} / (\\frac{1}{3}(1) + \\frac{2}{3}(3)) = -\\frac{1}{165} \\approx 0.61\\% \\] 4.4.3 Dont Pass The dont pass bet is basically the opposite of the pass line bet. It is a somewhat unpopular bet because it means you are betting against the shooter (and they dont tend to like that). The bet wins immediately on 2 or 3. It pushes on a 12. (In some casinos it wins on 3 or 12 and pushes on 2, but this does not affect the odds). If a point is established, you are then betting against the player making his point. You win if a 7 is rolled before they make their point, and you lose if they make the point. Note that the push on a 12 (or a 2) is necessary for the house to maintain its edge. If you were to have a bet that was truly the opposite of the pass line, it would mean that youd have a positive advantage in the game. The first roll has the following outcomes and probabilities: Outcome Probability Push (12) \\[ \\frac{1}{36} \\approx 2.78\\% \\] Win (2, 3) \\[ \\frac{1+2}{36} = \\frac{1}{12} \\approx 8.33\\% \\] Lose (7 or 11) \\[ \\frac{6+2}{36} = \\frac{2}{9} \\approx 22.22\\% \\] Continue \\[ \\frac{2}{3} \\approx 66.67\\% \\] The probability against making the points are simply the complements from the pass line bet table. These are: Point Probability of Occurring Probability of Win 4 or 10 \\[ 2 * \\frac{3}{36} = \\frac{1}{6} \\approx 16.67\\% \\] \\[ \\frac{2}{3} \\approx 66.67\\% \\] 5 or 9 \\[ 2 * \\frac{4}{36} = \\frac{2}{9} \\approx 22.22\\% \\] \\[ \\frac{3}{5} = 60\\% \\] 6 or 8 \\[ 2 * \\frac{5}{36} = \\frac{5}{18} \\approx 27.78\\% \\] \\[ \\frac{6}{11} \\approx 54.54\\% \\] Any \\[ \\frac{3+4+5}{18} = \\frac{2}{3} \\approx 66.67\\% \\] \\[ \\frac{196}{330} \\approx 59.39\\% \\] The total probability of winning is then: \\[ \\frac{1}{12} + \\frac{2}{3}\\frac{196}{330} = \\frac{949}{1980} \\approx 47.93\\% \\] The expected value of this bet is then: \\[ \\frac{949}{1980}(1) + \\frac{1}{36}(0) + \\frac{976}{1980}(-1) = -\\frac{27}{1980} = -\\frac{3}{220} \\approx -1.36\\% \\] This is actually a slightly better bet than the pass line bet. However, you will have to weather the stares (and perhaps a few words) from the people at the table who you are betting against. 4.4.4 Dont Pass Odds As with the pass line bet, you can also place an odds bet on your dont pass bet if a point is established. You are now betting that a 7 will be rolled before the point is made. This also pays true odds meaning that it pays 1-to-2 for 4 or 10, 2-to-3 for 5 or 9, and 5-to-6 for 6 or 8. 4.5 Summary Weve covered a lot in this page. The following table brings together our primary results in one place: Bet House Edge Pass Line 1.41% Dont Pass Line 1.36% Pass Line (with 1x odds) 0.81% Pass Line (with 2x odds) 0.61% Place: 6 or 8 1.52% Place: 5 or 9 4.00% Place: 4 or 10 6.67% Buy Bets 4.76% Big 6 or 8 9.09% Hard 6 or 8 9.09% Hard 4 or 10 11.11% Field (3-to-1 on 12) 2.78% Field (2-to-1 on 12) 5.56% Service: 2 or 12 13.89% Service: 3 or 11 11.11% Service: Any Craps 11.11% Service: Any 7 16.67% C&amp;E 11.11% "],["baccarat.html", "5 Baccarat 5.1 Overview 5.2 Simulation 5.3 Card Counting", " 5 Baccarat Baccarat Table 5.1 Overview Baccarat is often mentioned as a classy game (James Bond plays it in movies) and one where billionaire whales can win (or lose) millions of dollars in a single night. It also has one of the smallest house edges in the casino. According to Wikipedia it is played with 6-8 decks and follows a somewhat complicated set of rules for dealing cards to a player and a banker. Observers of the game bet on whether the player or banker will win. They also can bet on a tie. According to Wikipedia, the typical payouts and house advantages for these scenarios (with a 8-deck shoe) are below: Outcome Payout House Edge Banker Wins 19-to-20 1.06% Player Wins 1-to-1 1.24% Tie 8-to-1 14.4% 5.2 Simulation I wrote a Baccarat simulator in Java to confirm these numbers. The simulator played 1 billion hands of Baccarat following the classic Punto Banco rules as described on Wikipedia. This took about 4 minutes to run. The results were: Winner Occurrences Percentage Banker Wins 458,618,223 45.8618223% Player Wins 446,309,890 44.6309890% Tie 95,071,887 9.5071887% Total 1,000,000,000 100.0000000% To calculate the expected return and house advantage we need to include the payouts that result from the bets for each scenario. This is shown in the table below: Outcome Return(B) Return(P) Return(T) Banker Wins 1.95 0 0 Player Wins 0 2.00 0 Tie 1.00 1.00 9.00 Return(B) indicates the money you receive in each scenario if you bet on the banker winning. Similarly, Return(P) and Return(T) represent bets placed on the player and a tie. When multiplying these returns by the probability of each scenario, the expected returns and house advantages for each bet are: Bet Expected Return House Advantage Banker 98.94% 1.06% Player 98.77% 1.23% Tie 85.56% 14.44% These match the results from Wikipedia to within +/- .01%. If we wanted to get fancy, we could calculate confidence intervals around our estimates. To do this, we make use of the fact that the Bernoulli distribution has a variance of p(1-p). This means that when calculating p as an average of N observations we would expect a standard deviation of p(1-p) / sqrt(N) around our estimate of the mean. This allows us to create the following confidence intervals around our probabilities: Outcome Estimate Stdev(Estimate) Min(Estimate) Max(Estimate) Banker Wins 45.8618223% 0.00157571% 45.8570952% 45.8665494% Player Wins 44.6309890% 0.001572% 44.6262730% 44.635705% Tie 9.5071887% 0.000927541% 9.5044061% 9.5099713% The Min and Max values of the estimate are calculated using 3 standard deviations. This means that we have a 99% chance of the true probability being somewhere between these two values. We can use these min and max estimates to calculate the payouts. This time we get: Bet Expected Return House Advantage Banker 98.93 - 98.95% 1.05 - 1.07% Player 98.76 - 98.78% 1.22 - 1.24% Tie 85.54 - 85.59% 14.41 - 14.46% 1 billion hands are needed in order to get confidence intervals this small. It is pleasing to see that the exact values from Wikipedia fall into our confidence ranges. 5.3 Card Counting Since Baccarat is played from a 6- or 8-deck shoe, you might naturally think there is an opportunity to count cards. The article below provides a great summary of several experts on this subject, each of them indicating that card counting is not practical in this game: https://www.888casino.com/blog/baccarat-tips/card-counting-in-baccarat The reason for this is that - unlike Blackjack - there are not cards that clearly favor the player or the banker. There are also no choices made in the game (except for your bet size), meaning that you cant use your knowledge of the deck to play the cards differently. Ed Thorp does provide a card-counting strategy that can yield an advantage to bets made on the player in rare scenarios. A positive advantage of 0.329% occurs every 1,786 hands, which is far too rare to use to your advantage. John May (a baccarat author) developed a counting strategy for betting on a tie that he claims yields a 62% advantage in certain rare scenarios. However, these rare scenarios occur approximately once every 10,000 hands - again making it too rare to be useful. If a player played Baccarat 40 hours a week, this scenario would occur only once every three weeks. "],["blackjack.html", "6 Blackjack 6.1 Introduction 6.2 Basic Strategy 6.3 Simulation &amp; Analysis 6.4 Card Counting", " 6 Blackjack 6.1 Introduction Blackjack is one of the most appealing games to a mathematical gambler because we know that it can be beat with various card-counting techniques. My grandfather once told me he was in a casino playing blackjack and the dealer looked at him and said: I dont know if youve been counting cards, but I have. And if you ever wanted to increase your bet, now is the time. He said he increased his bet as advised, won the next 5 hands in a row, and then the dealer shuffled. When he asked the dealer how he did that, he said he was counting 5s and that 5s are the most important card in the deck: they make a dealers hand from 12 to 16. The fewer of them there are, the better it is for the player.. Later on in life I would learn that counting 5s is a strategy developed by Ed Thorp. Ed Thorp has an interesting history. He was a professor of mathematics and one of the first academics to investigate Blackjack probabilities using computer simulations in the early 1960s. He tested his card counting methods in Las Vegas and was able to win a substantial amount of money. (Wikipedia humorously refers to this as his applied research). He also published his results, including various card counting strategies in the book Beat the Dealer. When he was at MIT he also worked with Claude Shannon (the father of information theory) at beating Roulette by wearing a camera that would take pictures of the ball in motion and predict where it would land, but getting into all the fun that Ed and Claude had would take us down a rabbit hole Suffice it to say that the more you learn about Blackjack, especially with it being one of the games with the lowest house edge (even without card counting), and the more movies they make about the MIT Blackjack Team, the more interesting this game becomes. As such, it was one of the first games I simulated and analyzed in detail. 6.2 Basic Strategy The Wizard of Odds offers great tools to help players learn Basic Strategy, the mathematically optimal way of playing Blackjack against a newly shuffled deck of cards. Basic Strategy, 4-8 Decks, Dealer Stands on Soft 17 | Basic Strategy, 1 Deck, Dealer Stands on Soft 17 | When playing according to these strategies, the Wizard of Odds calculates that you have the following expected returns: Decks Stand on Soft 17 Double After Split Expected Return 1 Yes Yes 0.1839% 1 Yes No 0.0423% 1 No Yes -0.0072% 1 No No -0.1513% 6 Yes Yes -0.4026% 6 Yes No -0.5445% 6 No Yes -0.6151% 6 No No -0.7598% 6.3 Simulation &amp; Analysis I have written at least 2 programs to simulate and analyze Blackjack odds. Sadly, I have lost the first program I wrote. (And it was a beauty. It had a GUI that let you select the number of decks and specify if you wanted to use a theoretical, infinite deck, compute exact odds, or use a simulation. It would even show you the final strategy in a nice, pretty view.) One day, I might write another that does all the fun and flash things the first one did, but right now it is pretty basic. It isnt even able to calculate optimal strategy for games that allow doubling down or splitting. It is, however, able to reproduce the basic hit/stand strategy. Our results match the Wizards 100% for his 1-deck and 6-deck strategies against a dealer that stands on soft 17. 6.3.1 Expected Returns Amazingly, the Wizard shows how to calculate optimal strategy in Excel here. His final spreadsheet (which also includes the ability to analyze expected returns) is available on Google Docs here. The spreadsheet results are based on an infinitely large deck so that the probability of drawing specific cards never changes. They do provide a good way for us to ballpark the estimated returns in Blackjack under a variety of rules. In the table below we show the expected return for players that implement various parts of basic strategy. For example, a player who only knows the right places to hit and stand, will be at a 2.421% disadvantageous against the house. If you learn when to double down, that reduces to 1.087%. And if you learn when to split, it reduces to about 0.5% (depending on how many splits are allowed). This is the commonly-reported house edge for Blackjack, but it assumes you are playing basic strategy close to perfectly. Learning when to surrender takes a further 0.1% off the house edge. Actions Exp. Return Hit/Stand -2.421% Hit/Stand/Double -1.087% Hit/Stand/Double/Surrender -0.994% Hit/Stand/Double/Split (1 split only) -0.570% Hit/Stand/Double/Split (infinite splits) -0.429% Hit/Stand/Double/Split/Surrender (1 split only) -0.485% Hit/Stand/Double/Split/Surrender (infinite splits) -0.344% When I ran my simulator on a 6-deck game where only Hit/Stand/Double was allowed, it produced an expected return of -0.9746%, in line with the results above, but slightly better to the player. For finite decks, the Wizard produced the following expected returns (assuming the player plays optimal strategy for each game): Decks Dealer 17 Double After Split Exp. Return 1 STAND Y 0.1839% 1 STAND N 0.0423% 1 HIT Y -0.0072% 1 HIT N -0.1513% 6 STAND Y -0.4026% 6 STAND N -0.5445% 6 HIT Y -0.6151% 6 HIT N -0.7598% In all of these games he is also assuming the following rules: Player may re-split to four hands, except aces No drawing to split aces Notice that a single-deck game where the dealer stands on soft 17 actually provides odds that favor the player (which is why you wont find it in a casino). The 6-deck game is more common and provides a house edge between 0.40% and 0.76%, depending on some variations in rules. Lastly, there is one rule that the player should avoid at all costs: any table that pays 6-to-5 (1.2x) instead of 1.5x on Blackjack is hurting your odds immensely. The return on optimal strategy against infinite decks with infinite splits drops from -0.344% to -1.697%, increasing the house advantage almost 5x. Stick to tables that pay 1.5x on blackjack, and try to find ones where the dealer stands on soft 17. These will give you the best odds and let you enjoy more play time. 6.3.2 Probability of Blackjack We can also calculate the probability of getting blackjack on the first hand with different sized decks. As shown below, the probability of getting blackjack is (slightly) higher with a smaller number of decks: Decks Probability of BJ 1 4.826546003016592% 2 4.779686333084391% 3 4.764267990074442% 4 4.756596060943887% 5 4.752004752004752% 6 4.748948800395746% 7 4.746768383132020% 8 4.745134383688601% 6.4 Card Counting 6.4.1 Hi/Lo Count The most common card-counting technique is the Hi/Lo count. This assigns a point value of +1 to cards 2-6 and a value of -1 for all 10s, face cards, and aces. The player keeps a running counting (starting at zero with each new shoe). If there are 4 face cards dealt, the count will be -4. Note that this is a balanced count where there are 5 cards that have a -1 value and 5 that have a +1 value. This means the overall expected value of the count is zero. When the count goes positive it is in the players advantage, and when it goes negative it is in the houses advantage. You will also want to normalize the count based on how many cards are left in the deck. You do this by dividing the count by the estimated number of decks left in the shoe. In this way the count essentially correlates with the percentage of 10s and aces left in the deck. The premise of this strategy is that the more 10s and Aces are in the deck, the better it is for the player. After all, the player makes a lot of their money from blackjack (paying out 1.5x their bet) and from being able to double-down when a 10 is likely. The Wizard of Odds has a nice page on it here. I dont see any info on the overall advantage this stategy returns. The Wizard analyzes it in the context of additional rules that modify the strategy. These additional rules yield an expected return in the players advantage of 0.157% - 1.182%, depending on how many of the rules you learn, how deep into the deck the dealer goes, and how much you vary your bet when the count is good. There used to be pages that documented various side-counting strategies, mainly those that would keep a side count of Aces. I dont see these in his site anymore. 6.4.2 Ace/Five Count The Wizard of Odds has a nice page describing a simple Ace/Five count similar to what my grandfather observed in the casino. He describes the strategy with the following steps: Establish what your minimum and maximum bets will be. Usually the maximum will be 8, 16, or 32 times the minimum bet, or any power of 2, but you can use whatever bet spread you wish. At the beginning of each shoe, start with your minimum bet, and a count of zero. For each five observed, add one to the count. For each ace observed, subtract one from the count. If the count is greater than or equal to two, then double your last bet, up to your maximum bet. If the count is less than or equal to one, then make the minimum bet. Use basic strategy for all playing decisions. He claims this strategy produces the following advantages, depending on the size of your min/max bet spread: Spread Player Advantage Average Initial Bet 1-8 0.30% 2.7 1-16 0.45% 4.2 1-32 0.57% 7.1 He warns that this was built to work against a 6-8 deck game like you will commonly find in Vegas, but where the dealer stands on soft 17. If the dealer hits on soft 17, it costs the player 0.22%. 6.4.3 Continuous Shuffling Machines (CSMs) About the time that I got excited about getting back into Blackjack analysis is when I learned about the introduction of Continuous Shuffling Machines. These machines take past cards from the dealer and continuosly shuffle them into a new deck. The idea is that it provides a brand new deck each time without ever allowing the game to penetrate deeply into the shoe. This of course completely destroys the advantage of card counting where the benefit derives from knowing past cards and increases the deeper into the shoe you go. The Wizard of Odds also has a page on this (of course he does!). He says that the CSMs actually reduce the house edge anywhere from 0.014% (in an 8-deck game) to 0.113% (in a 1-deck game). But of course, they nullify any chance of turning the odds in your favor via card counting. "],["other-games.html", "7 Other Games", " 7 Other Games The remaining chapters in this book cover games that are not considered gambling or casino games. But these games are still fun to analyze. "],["chutes-and-ladders.html", "8 Chutes and Ladders 8.1 Overview 8.2 Markov Processes and Chains 8.3 Statistics", " 8 Chutes and Ladders Chutes and Ladders Board 8.1 Overview Chutes and Ladders is one of my least favorite games to play. Even though the dice introduce randomness into the game, it still feels like you are just going through the motions of a deterministic process, waiting to see who comes out the winner. There are no decisions to make and no way that you can impact the game or improve your odds of winning. It feels very passive. I remember when I was about 22, working at the University of Cincinnati, and thinking about how much I hate this game. I wondered how long the game takes to play on average. With the unfettered access university employees get to academic journals, I came across an article: How Long Is a Game of Snakes and Ladders? (S.C. Althoen, L. King and K.Schilling, The Mathematical Gazette, Vol. 77, No. 478, pp. 71-76, Mar. 1993). linke here Not only did this article provide an answer: 39.2 turns on average, it also provided an exact fractional representation of the expected game length: \\[ \\frac{225837582538403273407117496273279920181931269186581786048583}{5757472998140039232950575874628786131130999406013041613400} \\] I thought that was pretty bad-ass! The paper also explained how the entire game could be modeled as a state-absorbing Markov chain, which sounded fun to work with. Of course, it wasnt enough just to get the answer. I wanted to reproduce it myself and learn more about these Markov chains. So thats exactly what I did. 8.2 Markov Processes and Chains A Markov process is a process whose future state is entirely determined by its current state. It does not matter what has come before. The current state is enough to know what will come next. All you really need is some way to represent the current state, and then some kind of transition function you apply to the current state to get the next state. This can then be iterated forward in discrete steps to discover future states. A Markov chain refers to the model you build to describe the particular process. In Chutes-and-Ladders the current state can be modeled by a 101 element vector. This vector represents the 100 positions on the board (labeled 1 to 100) and the starting position (position 0) which is off the board. The player begins in position 0, so that we initialize our state to a vector of all zeroes except for a 1 in the first element. The transition matrix represents the roll of a die and what can happen to your player when that happens. With a 6-sided die there is a 1/6 chance of rolling each number, and each number indicates the number of states you will advance. Thus, if you are on space #10 you have a 1/6 chance of being on space #11 the next round, a 1/6 chance of being on space #12, and so on through space #16. This would be true if there were no chutes or ladders. Actually, there is a chute on space #16 that takes you back to space #6. So the transition matrix would need to be adjusted to show that you actually have a 1/6 chance of going to space #6 and a zero chance of going to #16. The R code below builds the appropriate initial state vector and transition matrix for the game: state0 &lt;- c(1, rep(0, 100)) T_matrix &lt;- matrix(0, nrow=101, ncol=101) for (i in 0:101) { for (j in 1:6) { next_space &lt;- i + j if (next_space &gt; 101) { # must land on last space exactly next_space &lt;- i } T_matrix[next_space, i] &lt;- T_matrix[next_space, i] + 1/6 } } df_special &lt;- tibble::tribble( ~type, ~from, ~to, &quot;L&quot;, 1, 38, &quot;L&quot;, 4, 14, &quot;L&quot;, 9, 31, &quot;L&quot;, 21, 42, &quot;L&quot;, 28, 84, &quot;L&quot;, 36, 44, &quot;L&quot;, 51, 67, &quot;L&quot;, 71, 91, &quot;L&quot;, 80, 100, &quot;C&quot;, 16, 6, &quot;C&quot;, 47, 26, &quot;C&quot;, 49, 11, &quot;C&quot;, 56, 53, &quot;C&quot;, 62, 19, &quot;C&quot;, 64, 60, &quot;C&quot;, 87, 24, &quot;C&quot;, 93, 73, &quot;C&quot;, 95, 75, &quot;C&quot;, 98, 78 ) for (i in 1:nrow(df_special)) { T_matrix[df_special$to[i]+1,] &lt;- T_matrix[df_special$to[i]+1,] + T_matrix[df_special$from[i]+1,] T_matrix[df_special$from[i]+1,] &lt;- 0 } We can then simulate a turn in the game simply by multiplying our state vector by the transition matrix. After one turn we have the following: state &lt;- state0 state &lt;- T_matrix %*% state as.numeric(state) ## [1] 0.0000000 0.0000000 0.1666667 0.1666667 0.0000000 0.1666667 0.1666667 ## [8] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 ## [15] 0.1666667 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 ## [22] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 ## [29] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 ## [36] 0.0000000 0.0000000 0.0000000 0.1666667 0.0000000 0.0000000 0.0000000 ## [43] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 ## [50] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 ## [57] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 ## [64] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 ## [71] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 ## [78] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 ## [85] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 ## [92] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 ## [99] 0.0000000 0.0000000 0.0000000 We have a 1/6 chance of ending up in spaces: 2, 3, 5, 14, 38. When we take the next step, these probabilities start to spread out: state &lt;- T_matrix %*% state as.numeric(state) ## [1] 0.00000000 0.00000000 0.00000000 0.02777778 0.00000000 0.05555556 ## [7] 0.11111111 0.11111111 0.11111111 0.00000000 0.05555556 0.05555556 ## [13] 0.02777778 0.00000000 0.05555556 0.02777778 0.00000000 0.02777778 ## [19] 0.02777778 0.02777778 0.02777778 0.00000000 0.00000000 0.00000000 ## [25] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 ## [31] 0.00000000 0.08333333 0.00000000 0.00000000 0.00000000 0.00000000 ## [37] 0.00000000 0.00000000 0.00000000 0.02777778 0.02777778 0.02777778 ## [43] 0.02777778 0.02777778 0.02777778 0.00000000 0.00000000 0.00000000 ## [49] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 ## [55] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 ## [61] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 ## [67] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 ## [73] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 ## [79] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 ## [85] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 ## [91] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 ## [97] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 They start to reflect the various ways the game can play out based upon our first roll and second roll. And of course, we could find the probabilities describing the board after N turns with the simple equation: \\[ x_N = T^N x_0 \\] 8.3 Statistics We can now ask ourselves questions such as: how many turns will it take before we have a 50% chance of ending the game? (i.e. what is the median length of a 1 player game?) state &lt;- state0 n_steps &lt;- 0 while(TRUE) { state &lt;- T_matrix %*% state n_steps &lt;- n_steps + 1 if (state[101] &gt;= 0.5) {break} } cat(paste0(&quot;Median Game Length = &quot;, n_steps)) ## Median Game Length = 32 While it is possible in theory for games to go on forever (you can always keep hitting those slides), we can put an upper bound on what is practical by measuring how many turns before we have a 99.9999% chance of finishing the game: state &lt;- state0 n_steps &lt;- 0 while(TRUE) { state &lt;- T_matrix %*% state n_steps &lt;- n_steps + 1 if (state[101] &gt;= 0.999999) {break} } cat(paste0(&quot;Max Game Length = &quot;, n_steps)) ## Max Game Length = 352 It is very unlikely that a 1-player game would go beyond 300 turns. With this upper bound in mind lets build a vector containing the probabilities of ending the game at each turn: state &lt;- state0 cdf_finish &lt;- rep(0,1000) for (i in 1:1000) { state &lt;- T_matrix %*% state cdf_finish[i] &lt;- state[101] } pdf_finish &lt;- diff(c(0, cdf_finish)) plot(pdf_finish, xlim=c(0, 300)) We can now answer all kinds of fun questions. What is the average length of a 1-player game: result &lt;- weighted.mean(x=1:1000, w=pdf_finish) cat(paste0(&quot;Average Length of Game = &quot;, result)) ## Average Length of Game = 39.225122308183 This is exactly the answer that was given in the paper. (Hoo-Wah!) But how many times do you play Chutes and Ladders by yourself? Lets tackle a topic that wasnt covered in the paper: the expected length of multi-player games. We can calculate this by producing a probability distribution indicating the probability that none of the players have finished the game and then taking the complement of this: cdf_still_playing &lt;- 1 - cdf_finish cdf_still_playing2 &lt;- cdf_still_playing ^ 2 cdf_finish2 &lt;- 1 - cdf_still_playing2 pdf_finish2 &lt;- diff(c(0, cdf_finish2)) plot(pdf_finish2) result &lt;- weighted.mean(x=1:1000, w=pdf_finish2) cat(paste0(&quot;Average Length of 2 Player Game = &quot;, result)) ## Average Length of 2 Player Game = 26.3309566420474 We can also do the same for any number of players: get_average_game_length &lt;- function(n_players) { cdf_still_playing &lt;- 1 - cdf_finish cdf_still_playing_n &lt;- cdf_still_playing ^ n_players cdf_finish_n &lt;- 1 - cdf_still_playing_n pdf_finish_n &lt;- diff(c(0, cdf_finish_n)) weighted.mean(x=1:1000, w=pdf_finish_n) } n_players &lt;- 1:4 avg_game_length &lt;- sapply(1:4, get_average_game_length) df_result &lt;- data.frame( n_players = n_players, avg_game_turns = avg_game_length, avg_game_minutes = avg_game_length * n_players * 10 / 60 ) knitr::kable(df_result) n_players avg_game_turns avg_game_minutes 1 39.22512 6.537520 2 26.33096 8.776986 3 21.72805 10.864025 4 19.26697 12.844650 In the table above we have added a column for the expected game length in minutes. This is assuming that each player takes 10 seconds to move. Notice that even though the game with more players ends in fewer turns, these games actually take longer because more people have to move on each turn. So next time someone asks if you want to play Chutes and Ladders, pull up these figures and youll know what youre signing up for (on average). Lets just hope you dont get stuck in one of those rare 300+ turn games! "],["war.html", "9 War 9.1 Overview 9.2 Simulation 9.3 Results", " 9 War 9.1 Overview One of the games that seems like a complete waste of time these days (although I admit I did enjoy playing it as a kid) is War. This is the game where you split the deck in half and then each person turns up a card. The person with the highest card wins the round and takes both cards for their pile. In the event of a tie, you have a war where you place 3 cards face-down and then 1 face-up. The face-up cards are compared and the winner takes all. Unless it is another tie, in which case you repeat the war again. There is no strategy in this game and no decisions to make. In fact, despite maybe some randomness in how you collect cards into a pile and how you shuffle, the outcome of the game is essentially known the minute the cards are divided. This makes it a simple game to simulate and answer some basic questions about the game. 9.2 Simulation The simulation can be found in the Java program com.futurestats.games.war.WarSimulator. One complexity that arose during the simulation was how to handle the cases where a war is in progress and a player runs out of cards. In this case, I decided the player that still had cards left wins the game. Wikipedia had this to say on the topic: Most descriptions of War are unclear about what happens if a player runs out of cards during a war. In some variants, that player immediately loses. In others, the player may play the last card in their deck as their face-up card for the remainder of the war or replay the game from the beginning. Other than this ambiguity, the coding of the simulation was very straight-forward. 9.3 Results I ran two simulations: one including Jokers in the deck and one without. In each case we simulated 100,000 games and recorded how many rounds the game lasted. The results are below: Simulation Avg. Rounds Min Rounds Max Rounds No Jokers 234.44686 5 2088 Jokers 270.48799 5 2396 On average, a game lasts 234-270 rounds (depending on whether you have Jokers or not). Jokers extend the game - which makes sense because they are hard cards to capture from your opponent. The shortest game observed was only 5 turns. This must have been a game with a long war with many ties since youd have to capture 26-27 cards in these 5 turns. The longest games were over 2,000 rounds. If you play quickly, you could probably do a round every 1-2 seconds. That means you can expect your game to last an average of 4-8 minutes. But dont be surprised if you end up in the long tail with games that can run as long as 40-80 minutes - especially if you use Jokers. "]]
